# Know your Habitat (CNN)

Develop a platform (web/android) that performs a reverse image search and identifies the objects present in the image. The user will click an image or make a short video, and the platform will classify the content of the image or video based on different classes such as:

- Name of the plant/flower/bird
- Academic buildings/offices/infrastructure
- Location (Mandi/South campus/North campus)

The code trains a convolutional neural network (CNN) using the VGG19 architecture to classify images into different categories. The model is trained using a dataset of images and their corresponding labels. After training, the model is saved and can be used for prediction. 

The code also includes an example of how to use the trained model to predict the class of an input image.

# Input
<img width="289" alt="image" src="https://user-images.githubusercontent.com/117291117/228690716-1e303515-1d80-487b-a657-61011dc00378.png">
<img width="289" alt="image" src="https://user-images.githubusercontent.com/117291117/228690805-91372af7-8335-436f-ba78-f02a32b15af4.png">

# Output
<img width="317" alt="image" src="https://user-images.githubusercontent.com/117291117/228690910-5a45ad1e-dd71-4655-ad8d-2cc640764306.png">
<img width="317" alt="image" src="https://user-images.githubusercontent.com/117291117/228690946-0755b4c4-d5fc-43ca-b235-c2208cb07f10.png">

